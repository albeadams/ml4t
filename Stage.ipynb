{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "122c5467-665c-4c68-8f07-4244879e5ae7",
   "metadata": {},
   "source": [
    "### Uses Paper Trade - test money\n",
    "##### https://alpaca.markets/docs/api-documentation/api-v2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27f732e7-bdf0-4b1e-a01b-31ec0f4fff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import time, datetime as dt\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "\n",
    "import alpha\n",
    "import alpaca\n",
    "import database as db\n",
    "from populate import download_data\n",
    "from rl_algos import TD3, ReplayBuffer, Actor, Critic\n",
    "from portfolios import Portfolio\n",
    "from history import *\n",
    "\n",
    "DataStore = db.DataStore()\n",
    "\n",
    "# to move to respective files...\n",
    "import gym\n",
    "from gym import spaces\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "59f4be2b-a2bc-4639-a0cb-5b53ca523f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockTraderEnvironment(gym.Env):\n",
    "    def __init__(self,\n",
    "                portfolio,\n",
    "                history, \n",
    "                short=False):\n",
    "        \n",
    "        self.portfolio = portfolio\n",
    "        self.indicators = history.indicators\n",
    "        self.prices = history.prices\n",
    "        self.symbol = history.symbol\n",
    "        self.short = short\n",
    "        \n",
    "        # <<train/val/test split>>\n",
    "        num_days = self.prices.shape[0]\n",
    "        training = int(.75* num_days)\n",
    "        validation = int(.3*training)\n",
    "        test = num_days-training\n",
    "        \n",
    "        self.price_train = self.prices.iloc[:(training-validation)]\n",
    "        self.indicator_train = self.indicators.iloc[:(training-validation)]\n",
    "        \n",
    "        self.training_days = self.price_train.shape[0]\n",
    "        print(f'{self.training_days} training days...', end='')\n",
    "        \n",
    "        self.price_validation = self.prices.iloc[(training-validation):training]\n",
    "        self.indicator_validation = self.indicators.iloc[(training-validation):training] \n",
    "        print(f'{self.price_validation.shape[0]} validation days...', end='')\n",
    "        \n",
    "        self.price_test = self.prices.iloc[training:]\n",
    "        self.indicator_test = self.indicators.iloc[training:]\n",
    "        # <<train/val/test split>>\n",
    "        \n",
    "        \n",
    "        num_indicators = self.indicators.shape[1]\n",
    "        assert num_indicators > 0, \"supply 1 or more indicators\"\n",
    "\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        # set space for alpha indicators at +- infinity...?\n",
    "        low_array = np.full((num_indicators), -np.inf)\n",
    "        high_array = np.full((num_indicators), np.inf)\n",
    "        self.observation_space = spaces.Box(low=low_array, high=high_array, dtype=np.float64)\n",
    "        \n",
    "        self.nS, self.nA = self.observation_space.shape[0], self.action_space.n\n",
    "        \n",
    "        self.previous_price = 0  # didn't exist before first day, so set previous_price to 0\n",
    "        first_day = self.indicator_train.index[0] # starting at first day indicators exist\n",
    "        self.prices = self.price_train.loc[first_day:] # rewriting prices to fit indicator list\n",
    "        \n",
    "        self.state = np.array(self.indicator_train.iloc[0]) # first day is inititial state\n",
    "        self.days = iter(self.price_train.index.values)\n",
    "        \n",
    "        # Iterate through days, checking action/reward, etc. in step...\n",
    "        self.trades = pd.DataFrame(0, index = self.price_train.index, columns = self.price_train.columns)\n",
    "        self.trades_dupl = self.trades.copy(deep = True)\n",
    "        \n",
    "        # position is how much long (positive), short (negative) or holding (zero)\n",
    "        self.portfolio.positions.append(self.symbol)\n",
    "        self.portfolio.position_amount[self.symbol] = 0  # how parse?\n",
    "        \n",
    "        self.end_data = False # marks end of dataset\n",
    "        self.evaluating = False\n",
    "\n",
    "        \n",
    "    def reset(self):\n",
    "        self.previous_price = 0\n",
    "        self.days = iter(self.price_train.index.values)\n",
    "        self.state = np.array(self.indicator_train.iloc[0])\n",
    "        self.trades = pd.DataFrame(0, index = self.price_train.index, columns = self.price_train.columns)\n",
    "        self.portfolio.position_amount[self.symbol] = 0\n",
    "        self.evaluating = False\n",
    "        self.end_data = False\n",
    "        \n",
    "\n",
    "    def eval_reset(self):\n",
    "        self.days = iter(self.price_validation.index.values)\n",
    "        self.eval_state = np.array(self.indicator_validation.iloc[0])\n",
    "        self.evaluating = True\n",
    "        self.end_data = False\n",
    "       \n",
    "    \n",
    "    def make_trade(self, action, current_price):\n",
    "        position = self.portfolio.position_amount[self.symbol]\n",
    "        if not self.short:\n",
    "            assert position >= 0, \"Error in logic - shorted position with shorting disabled\"\n",
    "        buysell_amount = 0\n",
    "        if action == 0 and position == 0:\n",
    "            buysell_amount = 100\n",
    "            self.portfolio.buy(self.symbol, buysell_amount, current_price)\n",
    "        elif action == 0 and position > 0:\n",
    "            buysell_amount = 50\n",
    "            self.portfolio.buy(self.symbol, buysell_amount, current_price)\n",
    "        elif action == 1 and position < 0:\n",
    "            if not self.short:\n",
    "                pass # for clarity\n",
    "            else:\n",
    "                buysell_amount = -50\n",
    "                self.portfolio.sell(self.symbol, -buysell_amount, current_price)\n",
    "        elif action == 1 and position == 0:\n",
    "            if not self.short:\n",
    "                pass\n",
    "            else:\n",
    "                buysell_amount = -100\n",
    "                self.portfolio.sell(self.symbol, -buysell_amount, current_price)\n",
    "        elif action == 1 and position > 0:\n",
    "            if not self.short:\n",
    "                buysell_amount = -position # sell off all of position if not shorting\n",
    "                self.portfolio.sell(self.symbol, -buysell_amount, current_price)\n",
    "            else:\n",
    "                buysell_amount = -position - 50 # sell off all of position if shorting and short additioanl 50\n",
    "                self.portfolio.sell(self.symbol, -buysell_amount, current_price)\n",
    "        elif action == 2:\n",
    "            pass # no action\n",
    "        return buysell_amount\n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        #https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py\n",
    "        err_msg = \"%r (%s) invalid\" % (action, type(action))\n",
    "        assert self.action_space.contains(action), action\n",
    "        \n",
    "        if self.end_data:\n",
    "            self.end_data = False\n",
    "        \n",
    "        #Calculate reward here... first day = 0\n",
    "        # 0 is buy, 1 is sell, 2 is hold\n",
    "        reward = 0\n",
    "        done = False\n",
    "        info = {}\n",
    "        try:\n",
    "            new_day = next(self.days)\n",
    "            if not self.evaluating:\n",
    "                current_price = self.price_train.loc[new_day, 'adjusted close']\n",
    "                self.state = self.indicator_train.loc[new_day]\n",
    "            else:\n",
    "                current_price = self.price_validation.loc[new_day, 'adjusted close']\n",
    "                self.state = self.indicator_validation.loc[new_day]\n",
    "                \n",
    "\n",
    "            if action == 0 and current_price > self.previous_price:\n",
    "                reward = 2\n",
    "            elif action == 0 and current_price < self.previous_price:\n",
    "                reward = -2\n",
    "            elif action == 1 and current_price < self.previous_price:\n",
    "                reward = 2\n",
    "            elif action == 1 and current_price > self.previous_price:\n",
    "                reward = -2\n",
    "            elif action == 2 and (current_price > self.previous_price or current_price < self.previous_price):\n",
    "                reward = -2 # or -1, don't puniash as much when hold and goes up/down?\n",
    "            elif action == 2 and current_price == self.previous_price:\n",
    "                reward = 2\n",
    "            else:\n",
    "                reward = 0\n",
    "                \n",
    "            if not self.evaluating:\n",
    "                buysell_amount = self.make_trade(action, current_price)\n",
    "                self.trades.loc[new_day] = buysell_amount\n",
    "            \n",
    "            info = {'current_day': new_day}\n",
    "            \n",
    "            self.previous_price = current_price\n",
    "            done = False\n",
    "        except StopIteration:\n",
    "            self.end_data = True\n",
    "            if not self.evaluating:\n",
    "                if self.trades.equals(self.trades_dupl):\n",
    "                    done = True\n",
    "                else:\n",
    "                    self.trades_dupl = self.trades.copy(deep = True)\n",
    "\n",
    "        return self.state, reward, done, info\n",
    "    \n",
    "    \n",
    "    def validation(self):\n",
    "        # use self.price_validation and indicator_validation...\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def render(self):\n",
    "        #ToDo - show progression via graph?\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8df68d3f-263d-4cff-aeac-4b31beda7ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio created - available cash: 10000\n",
      "Setting up experiment, loading history... 397 training days...170 validation days...Ready!\n"
     ]
    }
   ],
   "source": [
    "class Experiment:\n",
    "    def __init__(self, DataStore, td3_kwargs, portfolio, sym, dates=None, indicators='all', shorting_allowed=False):\n",
    "        print('Setting up experiment, loading history... ', end='')\n",
    "        self.available_cash = portfolio.cash_remaining\n",
    "        \n",
    "        #date format for range: dates=[dt.datetime(2000,1,1), dt.datetime(2020,12,31)]\n",
    "        self.history = History(DataStore, sym, dates, indicators=indicators)\n",
    "        self.history = self.history\n",
    "        self.indicators = self.history.indicators\n",
    "        self.prices = self.history.prices\n",
    "        \n",
    "        self.portfolio = portfolio\n",
    "        self.symbol = sym\n",
    "        \n",
    "        self.env = StockTraderEnvironment(self.portfolio, \n",
    "                                          self.history, \n",
    "                                          short=shorting_allowed)\n",
    "        \n",
    "        self.batch_size = 64 # not parameterized...\n",
    "        self.buffer = ReplayBuffer(self.env.nS, self.env.nA, max_buffer=int(1e6), batch_size=self.batch_size)\n",
    "        \n",
    "        self.max_action = 2  # 3 actions: [0,1,2], so 2 is max\n",
    "        print('Ready!')\n",
    "        \n",
    "        kwargs = {\n",
    "            \"state_dim\": self.env.nS,\n",
    "            \"action_dim\": self.env.nA,\n",
    "            \"max_action\": self.max_action,\n",
    "            \"discount\": td3_kwargs['discount'],\n",
    "            \"tau\": td3_kwargs['tau'],\n",
    "            \"policy_noise\": td3_kwargs['policy_noise']*self.max_action,            \n",
    "            \"noise_clip\": td3_kwargs['noise_clip']*self.max_action,\n",
    "            \"policy_freq\": td3_kwargs['policy_freq']\n",
    "        }\n",
    "        \n",
    "        self.policy = TD3(**kwargs)\n",
    "        self.expl_noise = td3_kwargs['expl_noise']\n",
    "        \n",
    "        \n",
    "    def eval_policy(self, eval_episodes=10):\n",
    "        print('Evaluating policy....')\n",
    "        avg_reward = 0.\n",
    "        for _ in range(eval_episodes):\n",
    "            self.env.eval_reset()\n",
    "            state = self.env.eval_state\n",
    "            done = False\n",
    "            while not self.env.end_data:\n",
    "                if type(state) is np.ndarray:\n",
    "                    s = torch.from_numpy(state) # not optimal - fix original data (and for tensor so not casting to float...)\n",
    "                else:\n",
    "                    s = torch.from_numpy(state.to_numpy())\n",
    "                action = self.policy.select_action(s)\n",
    "                action = np.argmax(action)\n",
    "                state, rwrd, _, _ = self.env.step(action)\n",
    "                avg_reward += rwrd\n",
    "\n",
    "        avg_reward /= eval_episodes\n",
    "\n",
    "        print(\"---------------------------------------\")\n",
    "        print(f\"Evaluation over {eval_episodes} episodes: {avg_reward:.3f}\")\n",
    "        print(\"---------------------------------------\")\n",
    "        return avg_reward\n",
    "\n",
    "        \n",
    "    def run(self, num_episodes, max_steps=int(1e6)):\n",
    "        \n",
    "        random_warmup = 25e3 # approx 4 years act randomly, is this enough?\n",
    "        total_days_run = 0\n",
    "        self.total_reward = 0\n",
    "        training_started = False\n",
    "        self.episode_reward = []\n",
    "        self.eval_avg_reward = []\n",
    "\n",
    "        for idx in range(num_episodes):\n",
    "            \n",
    "            self.env.reset()\n",
    "            state = self.env.state\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "            steps = 0\n",
    "            year = None\n",
    "            \n",
    "            for days_passed in range(self.env.training_days):\n",
    "\n",
    "                if total_days_run < random_warmup:\n",
    "                    action = self.env.action_space.sample()\n",
    "                else:\n",
    "                    #ToDo - what is this doing? https://github.com/sfujim/TD3/blob/master/main.py\n",
    "                    if type(state) is np.ndarray:\n",
    "                        s = torch.from_numpy(state) # not optimal - fix original data (and for tensor so not casting to float...)\n",
    "                    else:\n",
    "                        s = torch.from_numpy(state.to_numpy())\n",
    "                    action = (self.policy.select_action(s) + np.random.normal(0, self.max_action * self.expl_noise, size=self.env.nA)).clip(-self.max_action, self.max_action)\n",
    "                    action = np.argmax(action)\n",
    "            \n",
    "                next_state, reward, done, info = self.env.step(action)\n",
    "                \n",
    "                experience = [state, action, next_state, reward, done]\n",
    "                self.buffer.update(experience)\n",
    "                \n",
    "                self.total_reward += reward\n",
    "                episode_reward += reward\n",
    "                \n",
    "                if done:\n",
    "                    print(f'Converged after {total_days_run} days')\n",
    "                    break\n",
    "                \n",
    "                state = next_state\n",
    "                if total_days_run >= random_warmup:\n",
    "                    self.policy.train(self.buffer, self.batch_size)\n",
    "                    if not training_started:\n",
    "                        print('\\n----Training has begun---\\n')\n",
    "                        training_started = True\n",
    "                \n",
    "                if days_passed == self.env.training_days - 1:\n",
    "                    if num_episodes - idx - 1 == 0:\n",
    "                        print('Finished all episodes, did not converge')\n",
    "                    else:\n",
    "                        print(f'Finished episode without converging, {num_episodes - idx - 1} more episodes. {total_days_run} total days run. ', end='')\n",
    "                        \n",
    "                total_days_run += 1\n",
    "                \n",
    "            if not done:\n",
    "                #ToDo: run validation at end of training days when not converged\n",
    "                pass\n",
    "                \n",
    "            print(f'Episode reward {episode_reward}')\n",
    "            self.episode_reward.append(episode_reward)\n",
    "            \n",
    "        print(f'total reward {self.total_reward}')\n",
    "        self.eval_avg_reward.append(self.eval_policy(10))\n",
    "                    \n",
    "        #self.env.close() # not defined\n",
    "    \n",
    "fake_portfolio = Portfolio(use_alpaca=False)\n",
    "\n",
    "kwargs = {\n",
    "    \"discount\": 0.99,\n",
    "    \"tau\": 0.005,\n",
    "    \"policy_noise\": 0.2,            \n",
    "    \"noise_clip\": 0.5,\n",
    "    \"policy_freq\": 2,\n",
    "    \"expl_noise\": 0.1\n",
    "}\n",
    "\n",
    "exp1 = Experiment(DataStore, kwargs, dates=[dt.datetime(2018,1,1), dt.datetime(2020,12,31)], portfolio=fake_portfolio, sym='JPM', indicators=['SMA', 'OBV', 'AD'])\n",
    "\n",
    "#ToDo: check negation in replay buffer for done...? borrow replay buffer logic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "47397463-3376-4f88-b643-573955a3154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode without converging, 999 more episodes. 396 total days run. Episode reward -230\n",
      "Finished episode without converging, 998 more episodes. 793 total days run. Episode reward -210\n",
      "Finished episode without converging, 997 more episodes. 1190 total days run. Episode reward -320\n",
      "Finished episode without converging, 996 more episodes. 1587 total days run. Episode reward -216\n",
      "Finished episode without converging, 995 more episodes. 1984 total days run. Episode reward -228\n",
      "Finished episode without converging, 994 more episodes. 2381 total days run. Episode reward -252\n",
      "Finished episode without converging, 993 more episodes. 2778 total days run. Episode reward -206\n",
      "Finished episode without converging, 992 more episodes. 3175 total days run. Episode reward -296\n",
      "Finished episode without converging, 991 more episodes. 3572 total days run. Episode reward -254\n",
      "Finished episode without converging, 990 more episodes. 3969 total days run. Episode reward -272\n",
      "Finished episode without converging, 989 more episodes. 4366 total days run. Episode reward -294\n",
      "Finished episode without converging, 988 more episodes. 4763 total days run. Episode reward -190\n",
      "Finished episode without converging, 987 more episodes. 5160 total days run. Episode reward -244\n",
      "Finished episode without converging, 986 more episodes. 5557 total days run. Episode reward -250\n",
      "Finished episode without converging, 985 more episodes. 5954 total days run. Episode reward -288\n",
      "Finished episode without converging, 984 more episodes. 6351 total days run. Episode reward -280\n",
      "Finished episode without converging, 983 more episodes. 6748 total days run. Episode reward -266\n",
      "Finished episode without converging, 982 more episodes. 7145 total days run. Episode reward -252\n",
      "Finished episode without converging, 981 more episodes. 7542 total days run. Episode reward -262\n",
      "Finished episode without converging, 980 more episodes. 7939 total days run. Episode reward -224\n",
      "Finished episode without converging, 979 more episodes. 8336 total days run. Episode reward -248\n",
      "Finished episode without converging, 978 more episodes. 8733 total days run. Episode reward -296\n",
      "Finished episode without converging, 977 more episodes. 9130 total days run. Episode reward -208\n",
      "Finished episode without converging, 976 more episodes. 9527 total days run. Episode reward -236\n",
      "Finished episode without converging, 975 more episodes. 9924 total days run. Episode reward -226\n",
      "Finished episode without converging, 974 more episodes. 10321 total days run. Episode reward -288\n",
      "Finished episode without converging, 973 more episodes. 10718 total days run. Episode reward -364\n",
      "Finished episode without converging, 972 more episodes. 11115 total days run. Episode reward -292\n",
      "Finished episode without converging, 971 more episodes. 11512 total days run. Episode reward -202\n",
      "Finished episode without converging, 970 more episodes. 11909 total days run. Episode reward -254\n",
      "Finished episode without converging, 969 more episodes. 12306 total days run. Episode reward -238\n",
      "Finished episode without converging, 968 more episodes. 12703 total days run. Episode reward -262\n",
      "Finished episode without converging, 967 more episodes. 13100 total days run. Episode reward -228\n",
      "Finished episode without converging, 966 more episodes. 13497 total days run. Episode reward -206\n",
      "Finished episode without converging, 965 more episodes. 13894 total days run. Episode reward -244\n",
      "Finished episode without converging, 964 more episodes. 14291 total days run. Episode reward -222\n",
      "Finished episode without converging, 963 more episodes. 14688 total days run. Episode reward -246\n",
      "Finished episode without converging, 962 more episodes. 15085 total days run. Episode reward -230\n",
      "Finished episode without converging, 961 more episodes. 15482 total days run. Episode reward -176\n",
      "Finished episode without converging, 960 more episodes. 15879 total days run. Episode reward -330\n",
      "Finished episode without converging, 959 more episodes. 16276 total days run. Episode reward -280\n",
      "Finished episode without converging, 958 more episodes. 16673 total days run. Episode reward -314\n",
      "Finished episode without converging, 957 more episodes. 17070 total days run. Episode reward -270\n",
      "Finished episode without converging, 956 more episodes. 17467 total days run. Episode reward -234\n",
      "Finished episode without converging, 955 more episodes. 17864 total days run. Episode reward -242\n",
      "Finished episode without converging, 954 more episodes. 18261 total days run. Episode reward -214\n",
      "Finished episode without converging, 953 more episodes. 18658 total days run. Episode reward -272\n",
      "Finished episode without converging, 952 more episodes. 19055 total days run. Episode reward -228\n",
      "Finished episode without converging, 951 more episodes. 19452 total days run. Episode reward -276\n",
      "Finished episode without converging, 950 more episodes. 19849 total days run. Episode reward -328\n",
      "Finished episode without converging, 949 more episodes. 20246 total days run. Episode reward -282\n",
      "Finished episode without converging, 948 more episodes. 20643 total days run. Episode reward -220\n",
      "Finished episode without converging, 947 more episodes. 21040 total days run. Episode reward -210\n",
      "Finished episode without converging, 946 more episodes. 21437 total days run. Episode reward -222\n",
      "Finished episode without converging, 945 more episodes. 21834 total days run. Episode reward -282\n",
      "Finished episode without converging, 944 more episodes. 22231 total days run. Episode reward -236\n",
      "Finished episode without converging, 943 more episodes. 22628 total days run. Episode reward -344\n",
      "Finished episode without converging, 942 more episodes. 23025 total days run. Episode reward -240\n",
      "Finished episode without converging, 941 more episodes. 23422 total days run. Episode reward -304\n",
      "Finished episode without converging, 940 more episodes. 23819 total days run. Episode reward -250\n",
      "Finished episode without converging, 939 more episodes. 24216 total days run. Episode reward -272\n",
      "Finished episode without converging, 938 more episodes. 24613 total days run. Episode reward -290\n",
      "\n",
      "----Training has begun---\n",
      "\n",
      "Finished episode without converging, 937 more episodes. 25010 total days run. Episode reward -256\n",
      "Finished episode without converging, 936 more episodes. 25407 total days run. Episode reward -234\n",
      "Finished episode without converging, 935 more episodes. 25804 total days run. Episode reward -268\n",
      "Finished episode without converging, 934 more episodes. 26201 total days run. Episode reward -240\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-3f43aa32213c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-62b2d92dd30f>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, num_episodes, max_steps)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtotal_days_run\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mrandom_warmup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtraining_started\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n----Training has begun---\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml4t/rl_algos.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, replay_buffer, batch_size)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mcritic_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# Delayed policy updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml4t/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp1.run(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b2804d39-7cb2-4b1d-b0a6-0f4ab81e8274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(exp1.episode_reward)\n",
    "plt.ylabel('reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "03cad237-2b43-46d4-8cc4-eda9d829e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_orders(df, symbol):\n",
    "    orders = df.copy(deep = True)\n",
    "    orders.columns = ['Shares']\n",
    "    orders.insert(0, 'Symbol', ''.join(symbol))\n",
    "    orders.insert(1, 'Order', 0)\n",
    "\n",
    "    orders.ix[orders['Shares'] > 0, 'Order'] = \"BUY\"\n",
    "    orders.ix[orders['Shares'] < 0, 'Order'] = \"SELL\" \n",
    "\n",
    "    # make all positive since Sell/Buy is used\n",
    "    orders['Shares'] = orders['Shares'].abs().astype(int)\n",
    "\n",
    "    return orders\n",
    "\n",
    "# not factoring in commission or impact yet...\n",
    "def compute_portvals(experiment):                                                                                      \n",
    "\n",
    "    start_val = experiment.portfolio.start_value\n",
    "    prices = experiment.env.price_train\n",
    "    orders = experiment.env.trades.copy(deep=True)\n",
    "    orders.rename(columns={'adjusted close': 'Shares'}, inplace=True)\n",
    "    orders = orders.sort_index()\n",
    "    symbol = experiment.symbol\n",
    "    \n",
    "    start_date = orders.index[0]\n",
    "    end_date = orders.index[-1]\n",
    "    dates = pd.date_range(start_date, end_date)\n",
    "    \n",
    "    prices.ffill(axis=0, inplace=True)\n",
    "    prices.bfill(axis=0, inplace=True)\n",
    "    prices['Cash'] = 1.0\n",
    "\n",
    "    trades = prices.copy(deep = True)\n",
    "    trades.loc[:,:] = 0.0\n",
    "    trades.rename(columns={'adjusted close': symbol}, inplace=True)\n",
    "\n",
    "    for date, row in orders.iterrows():\n",
    "        if row[0] < 0:\n",
    "            trades.loc[date,symbol] = trades.loc[date,symbol] - row['Shares']\n",
    "            trades.loc[date,'Cash'] = trades.loc[date,'Cash'] + 1 # track commission multiplier\n",
    "        else:\n",
    "            trades.loc[date,symbol] = trades.loc[date,symbol] + row['Shares']\n",
    "            trades.loc[date,'Cash'] = trades.loc[date,'Cash'] + 1\n",
    "\n",
    "    print(trades)\n",
    "    sys.exit()\n",
    "\n",
    "    trades['Cash'] = (prices.iloc[:,:-1].mul(trades.iloc[:,:-1]).sum(axis=1)*-1).sub(commiss['Cash'],fill_value=0).sub(df_impact['Cash'],fill_value=0)\n",
    "\n",
    "    holdings = trades.copy(deep = True)\n",
    "    \n",
    "    # each row is sum of all previous rows (excluding Cash)\n",
    "    holdings.iloc[:,:-1] = holdings.rolling(len(holdings), min_periods=1).sum()\n",
    "    holdings['Cash'][0] = holdings['Cash'][0] + start_val\n",
    "    holdings.iloc[:,-1] = holdings.iloc[:,-1].rolling(len(holdings), min_periods=1).sum()\n",
    "\n",
    "    values = holdings.copy(deep = True)\n",
    "    values.loc[:,:] = 0\n",
    "    values = prices*holdings\n",
    "\n",
    "    portvals = values.copy(deep = True)\n",
    "    portvals = values.sum(axis=1)\n",
    "    portvals = portvals.to_frame()\n",
    "    return portvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9934e12a-27b3-4d97-8a68-dcd1e94b845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              JPM  Cash\n",
      "Date                   \n",
      "2017-01-03  100.0   1.0\n",
      "2017-01-04   50.0   1.0\n",
      "2017-01-05   50.0   1.0\n",
      "2017-01-06  154.0   1.0\n",
      "2017-01-09  100.0   1.0\n",
      "...           ...   ...\n",
      "2019-02-04   50.0   1.0\n",
      "2019-02-05    0.0   1.0\n",
      "2019-02-06    0.0   1.0\n",
      "2019-02-07    0.0   1.0\n",
      "2019-02-08   50.0   1.0\n",
      "\n",
      "[529 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/miniconda3/envs/ml4t/lib/python3.8/site-packages/pandas/core/frame.py:4147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n",
      "<ipython-input-79-bea6a918f961>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prices['Cash'] = 1.0\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/miniconda3/envs/ml4t/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3449: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "compute_portvals(exp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66540046-c23a-4503-aea9-be5d7c25a5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
