{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "122c5467-665c-4c68-8f07-4244879e5ae7",
   "metadata": {},
   "source": [
    "### Uses Paper Trade - test money\n",
    "##### https://alpaca.markets/docs/api-documentation/api-v2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f732e7-bdf0-4b1e-a01b-31ec0f4fff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import time, datetime as dt\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "\n",
    "import alpha\n",
    "import alpaca\n",
    "import database as db\n",
    "from populate import download_data\n",
    "from rl_algos import TD3, DDPG, ReplayBuffer, Actor, Critic\n",
    "from portfolios import Portfolio\n",
    "from history import *\n",
    "\n",
    "DataStore = db.DataStore()\n",
    "\n",
    "# to move to respective files...\n",
    "import gym\n",
    "from gym import spaces\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f4be2b-a2bc-4639-a0cb-5b53ca523f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockTraderEnvironment(gym.Env):\n",
    "    def __init__(self,\n",
    "                portfolio,\n",
    "                history, \n",
    "                short=False):\n",
    "        \n",
    "        self.portfolio = portfolio\n",
    "        self.indicators = history.indicators\n",
    "        self.indicators.drop(columns='adjusted close', inplace=True)\n",
    "        self.prices = history.prices\n",
    "        self.symbol = history.symbol\n",
    "        self.short = short\n",
    "        \n",
    "        # <<train/val/test split>>\n",
    "        num_days = self.prices.shape[0]\n",
    "        training = int(.75* num_days)\n",
    "        validation = int(.3*training)\n",
    "        test = num_days-training\n",
    "        \n",
    "        self.price_train = self.prices.iloc[:(training-validation)]\n",
    "        self.indicator_train = self.indicators.iloc[:(training-validation)]\n",
    "        \n",
    "        self.training_days = self.price_train.shape[0]\n",
    "        print(f'{self.training_days} training days...', end='')\n",
    "        \n",
    "        self.price_validation = self.prices.iloc[(training-validation):training]\n",
    "        self.indicator_validation = self.indicators.iloc[(training-validation):training] \n",
    "        print(f'{self.price_validation.shape[0]} validation days...', end='')\n",
    "        \n",
    "        self.price_test = self.prices.iloc[training:]\n",
    "        self.indicator_test = self.indicators.iloc[training:]\n",
    "        # <<train/val/test split>>\n",
    "        \n",
    "        \n",
    "        num_indicators = self.indicators.shape[1]\n",
    "        assert num_indicators > 0, \"supply 1 or more indicators\"\n",
    "\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        # set space for alpha indicators at +- infinity...?\n",
    "        low_array = np.full((num_indicators), -np.inf)\n",
    "        high_array = np.full((num_indicators), np.inf)\n",
    "        self.observation_space = spaces.Box(low=low_array, high=high_array, dtype=np.float64)\n",
    "        \n",
    "        self.nS, self.nA = self.observation_space.shape[0], self.action_space.n\n",
    "        \n",
    "        self.previous_price = 0  # didn't exist before first day, so set previous_price to 0\n",
    "        first_day = self.indicator_train.index[0] # starting at first day indicators exist\n",
    "        self.prices = self.price_train.loc[first_day:] # rewriting prices to fit indicator list\n",
    "        \n",
    "        self.state = np.array(self.indicator_train.iloc[0]) # first day is inititial state\n",
    "        self.days = iter(self.price_train.index.values)\n",
    "        \n",
    "        # Iterate through days, checking action/reward, etc. in step...\n",
    "        self.trades = pd.DataFrame(0, index = self.price_train.index, columns = self.price_train.columns)\n",
    "        self.trades_dupl = self.trades.copy(deep = True)\n",
    "        \n",
    "        # position is how much long (positive), short (negative) or holding (zero)\n",
    "        self.portfolio.positions.append(self.symbol)\n",
    "        self.portfolio.position_amount[self.symbol] = 0  # how parse?\n",
    "        \n",
    "        self.end_data = False # marks end of dataset\n",
    "\n",
    "        \n",
    "    def reset(self):\n",
    "        self.previous_price = 0\n",
    "        self.days = iter(self.price_train.index.values)\n",
    "        self.state = np.array(self.indicator_train.iloc[0])\n",
    "        self.trades = pd.DataFrame(0, index = self.price_train.index, columns = self.price_train.columns)\n",
    "        self.portfolio.position_amount[self.symbol] = 0\n",
    "        self.portfolio.cash_remaining = self.portfolio.start_value\n",
    "        self.end_data = False\n",
    "        \n",
    "\n",
    "    def eval_reset(self):\n",
    "        self.eval_days = iter(self.price_validation.index.values)\n",
    "        self.eval_state = np.array(self.indicator_validation.iloc[0])\n",
    "        self.eval_end_data = False\n",
    "        self.eval_previous_price = 0\n",
    "        \n",
    "    \n",
    "    def eval_step(self, action):\n",
    "        err_msg = \"%r (%s) invalid\" % (action, type(action))\n",
    "        assert self.action_space.contains(action), action\n",
    "        \n",
    "        if self.eval_end_data:\n",
    "            self.eval_end_data = False\n",
    "        \n",
    "        reward = 0\n",
    "        done = False\n",
    "        info = {}\n",
    "        try:\n",
    "            new_day = next(self.eval_days)\n",
    "            current_price = self.price_validation.loc[new_day, 'adjusted close']\n",
    "            self.state = self.indicator_validation.loc[new_day]\n",
    "\n",
    "            if action == 0 and current_price > self.eval_previous_price:\n",
    "                reward = 2\n",
    "            elif action == 0 and current_price < self.eval_previous_price:\n",
    "                reward = -2\n",
    "            elif action == 1 and current_price < self.eval_previous_price:\n",
    "                reward = 2\n",
    "            elif action == 1 and current_price > self.eval_previous_price:\n",
    "                reward = -2\n",
    "            elif action == 2 and (current_price > self.eval_previous_price or current_price < self.eval_previous_price):\n",
    "                reward = -2 # or -1, don't puniash as much when hold and goes up/down?\n",
    "            elif action == 2 and current_price == self.eval_previous_price:\n",
    "                reward = 2\n",
    "            else:\n",
    "                reward = 0\n",
    "            \n",
    "            info = {'current_day': new_day}\n",
    "            \n",
    "            self.eval_previous_price = current_price\n",
    "            done = False\n",
    "        except StopIteration:\n",
    "            self.eval_end_data = True\n",
    "\n",
    "        return self.state, reward, done, info\n",
    "    \n",
    "    \n",
    "    def make_trade(self, action, current_price):\n",
    "        position = self.portfolio.position_amount[self.symbol]\n",
    "        if not self.short:\n",
    "            assert position >= 0, \"Error in logic - shorted position with shorting disabled\"\n",
    "        buysell_amount = 0\n",
    "        if action == 0 and position == 0:\n",
    "            buysell_amount = 100\n",
    "            self.portfolio.buy(self.symbol, buysell_amount, current_price)\n",
    "        elif action == 0 and position > 0:\n",
    "            buysell_amount = 50\n",
    "            self.portfolio.buy(self.symbol, buysell_amount, current_price)\n",
    "        elif action == 1 and position < 0:\n",
    "            if not self.short:\n",
    "                pass # for clarity\n",
    "            else:\n",
    "                buysell_amount = -50\n",
    "                self.portfolio.sell(self.symbol, -buysell_amount, current_price)\n",
    "        elif action == 1 and position == 0:\n",
    "            if not self.short:\n",
    "                pass\n",
    "            else:\n",
    "                buysell_amount = -100\n",
    "                self.portfolio.sell(self.symbol, -buysell_amount, current_price)\n",
    "        elif action == 1 and position > 0:\n",
    "            if not self.short:\n",
    "                buysell_amount = -position # sell off all of position if not shorting\n",
    "                self.portfolio.sell(self.symbol, -buysell_amount, current_price)\n",
    "            else:\n",
    "                buysell_amount = -position - 50 # sell off all of position if shorting and short additioanl 50\n",
    "                self.portfolio.sell(self.symbol, -buysell_amount, current_price)\n",
    "        elif action == 2:\n",
    "            pass # no action\n",
    "        return buysell_amount\n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        #https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py\n",
    "        err_msg = \"%r (%s) invalid\" % (action, type(action))\n",
    "        assert self.action_space.contains(action), action\n",
    "        \n",
    "        if self.end_data:\n",
    "            self.end_data = False\n",
    "        \n",
    "        #Calculate reward here... first day = 0\n",
    "        # 0 is buy, 1 is sell, 2 is hold\n",
    "        reward = 0\n",
    "        done = False\n",
    "        info = {}\n",
    "        try:\n",
    "            new_day = next(self.days)\n",
    "\n",
    "            current_price = self.price_train.loc[new_day, 'adjusted close']\n",
    "            self.state = self.indicator_train.loc[new_day]\n",
    "\n",
    "            right_choice = 'none'\n",
    "            if action == 0 and current_price > self.previous_price:\n",
    "                reward = 1\n",
    "                right_choice = 'buy'\n",
    "            elif action == 0 and current_price < self.previous_price:\n",
    "                reward = -1\n",
    "                right_choice = 'sell'\n",
    "            elif action == 0 and current_price == self.previous_price:\n",
    "                reward = -1\n",
    "                right_choice = 'hold'\n",
    "            elif action == 1 and current_price < self.previous_price:\n",
    "                reward = 1\n",
    "                right_choice = 'sell'\n",
    "            elif action == 1 and current_price > self.previous_price:\n",
    "                reward = -1\n",
    "                right_choice = 'buy'\n",
    "            elif action == 1 and current_price == self.previous_price:\n",
    "                reward = -1\n",
    "                right_choice = 'hold'\n",
    "            elif action == 2 and current_price != self.previous_price:\n",
    "                reward = -1 # or -1, don't puniash as much when hold and goes up/down?\n",
    "                right_choice = 'buy or sell'\n",
    "            elif action == 2 and current_price == self.previous_price:\n",
    "                reward = 1\n",
    "                right_choice = 'hold'\n",
    "            else:\n",
    "                print(current_price, self.previous_price, action)\n",
    "                reward = 0\n",
    " \n",
    "            \n",
    "            buysell_amount = self.make_trade(action, current_price)\n",
    "            self.trades.loc[new_day] = buysell_amount\n",
    "\n",
    "            info = {'current_day': new_day, \n",
    "                    'current_price': current_price, \n",
    "                    'buysell_amount': buysell_amount, \n",
    "                    'right_choice': right_choice}            \n",
    "            \n",
    "            self.previous_price = current_price\n",
    "            done = False\n",
    "        except StopIteration:\n",
    "            self.end_data = True\n",
    "            done = True\n",
    "            if self.trades.equals(self.trades_dupl):\n",
    "                done = True\n",
    "                print('Converged')\n",
    "            else:\n",
    "                self.trades_dupl = self.trades.copy(deep = True)\n",
    "                \n",
    "            info = {'current_day': None, \n",
    "                    'current_price': None, \n",
    "                    'buysell_amount': None}\n",
    "\n",
    "        return self.state, reward, done, info\n",
    "    \n",
    "    \n",
    "    def render(self):\n",
    "        #ToDo - show progression via graph?\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8df68d3f-263d-4cff-aeac-4b31beda7ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(self, DataStore, td3_kwargs, portfolio, sym, dates=None, indicators='all', shorting_allowed=False):\n",
    "        print('Setting up experiment, loading history... ', end='')\n",
    "        self.available_cash = portfolio.cash_remaining\n",
    "        \n",
    "        #date format for range: dates=[dt.datetime(2000,1,1), dt.datetime(2020,12,31)]\n",
    "        self.history = History(DataStore, sym, dates, indicators=indicators)\n",
    "        self.indicators = self.history.indicators\n",
    "        self.prices = self.history.prices\n",
    "        \n",
    "        self.portfolio = portfolio\n",
    "        self.symbol = sym\n",
    "        \n",
    "        self.env = StockTraderEnvironment(self.portfolio, \n",
    "                                          self.history, \n",
    "                                          short=shorting_allowed)\n",
    "        \n",
    "        self.batch_size = 64 # not parameterized...\n",
    "        self.buffer = ReplayBuffer(self.env.nS, self.env.nA, max_buffer=50000, batch_size=self.batch_size)\n",
    "        \n",
    "        self.max_action = 2.0  # 3 actions: [0,1,2], so 2 is max\n",
    "        print('Ready!')\n",
    "        \n",
    "        kwargs = {\n",
    "            \"state_dim\": self.env.nS,\n",
    "            \"action_dim\": self.env.nA,\n",
    "            \"max_action\": self.max_action,\n",
    "            \"discount\": td3_kwargs['discount'],\n",
    "            \"tau\": td3_kwargs['tau'],\n",
    "            \"policy_noise\": td3_kwargs['policy_noise']*self.max_action,            \n",
    "            \"noise_clip\": td3_kwargs['noise_clip']*self.max_action,\n",
    "            \"policy_freq\": td3_kwargs['policy_freq']\n",
    "        }\n",
    "        \n",
    "        self.policy = TD3(**kwargs)\n",
    "        #self.policy = DDPG(**kwargs)\n",
    "        #self.policy = DuelingDDQN(**kwargs)\n",
    "        self.expl_noise = td3_kwargs['expl_noise']\n",
    "        self.expl_min = 0\n",
    "        self.delta = (self.expl_noise - self.expl_min)/50000\n",
    "        \n",
    "        \n",
    "    def eval_policy(self, eval_episodes=10):\n",
    "        avg_reward = 0.\n",
    "        for _ in range(eval_episodes):\n",
    "            self.env.eval_reset()\n",
    "            state = self.env.eval_state\n",
    "            done = False\n",
    "            while not self.env.eval_end_data:\n",
    "                state = state.astype(float)\n",
    "                if type(state) is np.ndarray:\n",
    "                    s = torch.from_numpy(state) # not optimal - fix original data (and for tensor so not casting to float...)\n",
    "                else:\n",
    "                    s = torch.from_numpy(state.to_numpy())\n",
    "                action = self.policy.select_action(s)\n",
    "                action = np.argmax(action)\n",
    "                state, rwrd, _, _ = self.env.eval_step(action)\n",
    "                avg_reward += rwrd\n",
    "\n",
    "        avg_reward /= eval_episodes\n",
    "\n",
    "        print(\"---------------------------------------\")\n",
    "        print(f\"Evaluation over {eval_episodes} episodes: {avg_reward:.3f}\")\n",
    "        print(\"---------------------------------------\")\n",
    "        return avg_reward\n",
    "\n",
    "        \n",
    "    def run(self, num_episodes, max_steps=int(1e6), warmup=25e3):\n",
    "        \n",
    "        random_warmup = warmup\n",
    "        total_days_run = 0\n",
    "        self.total_reward = 0\n",
    "        training_started = False\n",
    "        self.episode_reward = []\n",
    "        self.eval_avg_reward = []\n",
    "        self.action_match = []\n",
    "        \n",
    "        wrong = 0\n",
    "        \n",
    "        #self.eval_policy()\n",
    "\n",
    "        for idx in range(num_episodes):\n",
    "            \n",
    "            self.env.reset()\n",
    "            state = self.env.state\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "            steps = 0\n",
    "            year = None\n",
    "            \n",
    "            for days_passed in range(self.env.training_days+1):\n",
    "                \n",
    "                train = True\n",
    "\n",
    "                if total_days_run < random_warmup:\n",
    "                    action = self.env.action_space.sample()\n",
    "                else:\n",
    "                    #ToDo - what is this doing? https://github.com/sfujim/TD3/blob/master/main.py\n",
    "                    state = state.astype(float)\n",
    "                    if type(state) is np.ndarray:\n",
    "                        s = torch.from_numpy(state) # not optimal - fix original data (and for tensor so not casting to float...)\n",
    "                    else:\n",
    "                        s = torch.from_numpy(state.to_numpy())\n",
    "                    #self.expl_noise = max(self.expl_noise-self.delta, self.expl_min)\n",
    "                    action = (self.policy.select_action(s) + np.random.normal(0, self.max_action * self.expl_noise, size=self.env.nA)).clip(-self.max_action, self.max_action)\n",
    "                    x = action\n",
    "                    action = np.argmax(action)\n",
    "                    train = False\n",
    "                        \n",
    "                next_state, reward, done, info = self.env.step(action)\n",
    "                \n",
    "                if reward < 0: wrong += 1\n",
    "                    \n",
    "#                 if not train:          \n",
    "#                     if reward < 0:\n",
    "#                         print('wrong choice', x, action, info['right_choice'])\n",
    "#                     else:\n",
    "#                         try:\n",
    "#                             print('right choice', x, action, info['right_choice'])\n",
    "#                         except:\n",
    "#                             pass\n",
    "                \n",
    "                experience = [state, action, next_state, reward, done]\n",
    "                self.buffer.update(experience)\n",
    "                \n",
    "                self.total_reward += reward\n",
    "                episode_reward += reward\n",
    "                \n",
    "                state = next_state\n",
    "                if total_days_run >= random_warmup:\n",
    "                    self.policy.train(self.buffer, self.batch_size)\n",
    "                    if not training_started:\n",
    "                        print('\\n----Training has begun---\\n')\n",
    "                        training_started = True\n",
    "                \n",
    "                if done:\n",
    "                    print(f'{num_episodes - idx - 1} more episodes. {total_days_run} total days run. ', end='')\n",
    "                    \n",
    "                total_days_run += 1\n",
    "                \n",
    "            print(f'Episode reward {episode_reward}; wrong = {wrong}')\n",
    "            wrong = 0\n",
    "            self.episode_reward.append(episode_reward)\n",
    "            \n",
    "        print(f'total reward {self.total_reward}')\n",
    "        \n",
    "        self.eval_policy()\n",
    "                    \n",
    "        #self.env.close() # not defined\n",
    "    \n",
    "fake_portfolio = Portfolio(use_alpaca=False)\n",
    "\n",
    "kwargs = {\n",
    "    \"discount\": 0.9, #0.99\n",
    "    \"tau\": 0.01, # 0.005,  # soft update\n",
    "    \"policy_noise\": 0.2, #0.2,            \n",
    "    \"noise_clip\": 0.5,\n",
    "    \"policy_freq\": 2, #2\n",
    "    \"expl_noise\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89c5e422-4af4-4a9f-a1f4-cae4be5928e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataStore.list_indicator_symbols()\n",
    "#exp1.env.price_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47397463-3376-4f88-b643-573955a3154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [dt.datetime(2008,1,1), dt.datetime(2010,12,31)]\n",
    "sym = 'JPM'\n",
    "indicators = ['SMA','OBV', 'AD', 'BBANDS', 'MFI', 'SAR', 'T3', 'MOM', 'MIDPRICE', 'WMA']\n",
    "# exp1 = Experiment(DataStore, \n",
    "#                   kwargs, \n",
    "#                   dates=dates, \n",
    "#                   portfolio=fake_portfolio, \n",
    "#                   sym='JPM', \n",
    "#                   indicators=indicators,\n",
    "#                   shorting_allowed=True)\n",
    "# exp1.run(100, warmup=25e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24abf49-d717-4705-bf22-76a182a54456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03cad237-2b43-46d4-8cc4-eda9d829e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_orders(df, symbol):\n",
    "    orders = df.copy(deep = True)\n",
    "    orders.columns = ['Shares']\n",
    "    orders.insert(0, 'Symbol', ''.join(symbol))\n",
    "    orders.insert(1, 'Order', 0)\n",
    "\n",
    "    orders.ix[orders['Shares'] > 0, 'Order'] = \"BUY\"\n",
    "    orders.ix[orders['Shares'] < 0, 'Order'] = \"SELL\" \n",
    "\n",
    "    # make all positive since Sell/Buy is used\n",
    "    orders['Shares'] = orders['Shares'].abs().astype(int)\n",
    "\n",
    "    return orders\n",
    "\n",
    "# not factoring in commission or impact yet...\n",
    "def compute_portvals(experiment):                                                                                      \n",
    "\n",
    "    start_val = experiment.portfolio.start_value\n",
    "    prices = experiment.env.price_train\n",
    "    orders = experiment.env.trades.copy(deep=True)\n",
    "    orders.rename(columns={'adjusted close': 'Shares'}, inplace=True)\n",
    "    orders = orders.sort_index()\n",
    "    symbol = experiment.symbol\n",
    "    \n",
    "    start_date = orders.index[0]\n",
    "    end_date = orders.index[-1]\n",
    "    dates = pd.date_range(start_date, end_date)\n",
    "    \n",
    "    prices.ffill(axis=0, inplace=True)\n",
    "    prices.bfill(axis=0, inplace=True)\n",
    "    prices['Cash'] = 1.0\n",
    "\n",
    "    trades = prices.copy(deep = True)\n",
    "    trades.loc[:,:] = 0.0\n",
    "    trades.rename(columns={'adjusted close': symbol}, inplace=True)\n",
    "\n",
    "    for date, row in orders.iterrows():\n",
    "        if row[0] < 0:\n",
    "            trades.loc[date,symbol] = trades.loc[date,symbol] - row['Shares']\n",
    "            trades.loc[date,'Cash'] = trades.loc[date,'Cash'] + 1 # track commission multiplier\n",
    "        else:\n",
    "            trades.loc[date,symbol] = trades.loc[date,symbol] + row['Shares']\n",
    "            trades.loc[date,'Cash'] = trades.loc[date,'Cash'] + 1\n",
    "\n",
    "    print(trades)\n",
    "    sys.exit()\n",
    "\n",
    "    trades['Cash'] = (prices.iloc[:,:-1].mul(trades.iloc[:,:-1]).sum(axis=1)*-1).sub(commiss['Cash'],fill_value=0).sub(df_impact['Cash'],fill_value=0)\n",
    "\n",
    "    holdings = trades.copy(deep = True)\n",
    "    \n",
    "    # each row is sum of all previous rows (excluding Cash)\n",
    "    holdings.iloc[:,:-1] = holdings.rolling(len(holdings), min_periods=1).sum()\n",
    "    holdings['Cash'][0] = holdings['Cash'][0] + start_val\n",
    "    holdings.iloc[:,-1] = holdings.iloc[:,-1].rolling(len(holdings), min_periods=1).sum()\n",
    "\n",
    "    values = holdings.copy(deep = True)\n",
    "    values.loc[:,:] = 0\n",
    "    values = prices*holdings\n",
    "\n",
    "    portvals = values.copy(deep = True)\n",
    "    portvals = values.sum(axis=1)\n",
    "    portvals = portvals.to_frame()\n",
    "    return portvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9934e12a-27b3-4d97-8a68-dcd1e94b845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_portvals(exp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a1e7a41d-29fd-4519-bf56-10e30ba0a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "667d7986-0cd7-48c3-a965-15d1d3be70ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [dt.datetime(2008,1,1), dt.datetime(2010,12,31)]\n",
    "sym = 'JPM'\n",
    "indicators = ['SMA','OBV', 'AD', 'BBANDS', 'MFI', 'SAR', 'T3', 'MOM', 'MIDPRICE', 'WMA']\n",
    "history = History(DataStore, sym, dates, indicators=indicators)\n",
    "indicators = history.indicators\n",
    "prices = history.prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91513028-1987-4033-a91f-93a69758ec4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjusted close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-02</th>\n",
       "      <td>30.060001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-03</th>\n",
       "      <td>29.853280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>29.176093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-07</th>\n",
       "      <td>29.468352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-08</th>\n",
       "      <td>28.299313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            adjusted close\n",
       "Date                      \n",
       "2008-01-02       30.060001\n",
       "2008-01-03       29.853280\n",
       "2008-01-04       29.176093\n",
       "2008-01-07       29.468352\n",
       "2008-01-08       28.299313"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c356664-96a9-4d72-9c90-9a12e9a9a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indicators = indicators.iloc[:,1:]\n",
    "indicators.rename(columns={'adjusted close': 'close'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7031bafd-7892-4d71-b7f3-d72ef240e173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>SMA</th>\n",
       "      <th>OBV</th>\n",
       "      <th>Chaikin A/D</th>\n",
       "      <th>Real Upper Band</th>\n",
       "      <th>Real Middle Band</th>\n",
       "      <th>Real Lower Band</th>\n",
       "      <th>MFI</th>\n",
       "      <th>SAR</th>\n",
       "      <th>T3</th>\n",
       "      <th>MOM</th>\n",
       "      <th>MIDPRICE</th>\n",
       "      <th>WMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-02</th>\n",
       "      <td>30.0600005186</td>\n",
       "      <td>31.1368</td>\n",
       "      <td>-142498600.0</td>\n",
       "      <td>1.626332e+08</td>\n",
       "      <td>31.7512</td>\n",
       "      <td>31.1368</td>\n",
       "      <td>30.5223</td>\n",
       "      <td>44.7185</td>\n",
       "      <td>33.5787</td>\n",
       "      <td>31.5512</td>\n",
       "      <td>-0.4580</td>\n",
       "      <td>30.9037</td>\n",
       "      <td>31.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-03</th>\n",
       "      <td>29.8532800976</td>\n",
       "      <td>31.0191</td>\n",
       "      <td>-159649300.0</td>\n",
       "      <td>1.501074e+08</td>\n",
       "      <td>31.6972</td>\n",
       "      <td>31.0191</td>\n",
       "      <td>30.3410</td>\n",
       "      <td>46.8154</td>\n",
       "      <td>33.4331</td>\n",
       "      <td>31.4181</td>\n",
       "      <td>-1.1767</td>\n",
       "      <td>30.8181</td>\n",
       "      <td>30.9294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>29.1760925119</td>\n",
       "      <td>30.8695</td>\n",
       "      <td>-185523100.0</td>\n",
       "      <td>1.375022e+08</td>\n",
       "      <td>31.9971</td>\n",
       "      <td>30.8695</td>\n",
       "      <td>29.7420</td>\n",
       "      <td>34.6668</td>\n",
       "      <td>33.2498</td>\n",
       "      <td>31.2575</td>\n",
       "      <td>-1.4955</td>\n",
       "      <td>30.4154</td>\n",
       "      <td>30.6566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-07</th>\n",
       "      <td>29.4683524173</td>\n",
       "      <td>30.6233</td>\n",
       "      <td>-159879000.0</td>\n",
       "      <td>1.544779e+08</td>\n",
       "      <td>32.2614</td>\n",
       "      <td>30.6233</td>\n",
       "      <td>28.9851</td>\n",
       "      <td>35.1914</td>\n",
       "      <td>32.9925</td>\n",
       "      <td>31.0516</td>\n",
       "      <td>-2.4627</td>\n",
       "      <td>30.2479</td>\n",
       "      <td>30.2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-08</th>\n",
       "      <td>28.2993127955</td>\n",
       "      <td>30.4915</td>\n",
       "      <td>-193525000.0</td>\n",
       "      <td>1.295549e+08</td>\n",
       "      <td>32.2283</td>\n",
       "      <td>30.4915</td>\n",
       "      <td>28.7546</td>\n",
       "      <td>20.4535</td>\n",
       "      <td>32.6870</td>\n",
       "      <td>30.8224</td>\n",
       "      <td>-1.3183</td>\n",
       "      <td>29.9841</td>\n",
       "      <td>30.0907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Close      SMA          OBV   Chaikin A/D  \\\n",
       "2008-01-02  30.0600005186  31.1368 -142498600.0  1.626332e+08   \n",
       "2008-01-03  29.8532800976  31.0191 -159649300.0  1.501074e+08   \n",
       "2008-01-04  29.1760925119  30.8695 -185523100.0  1.375022e+08   \n",
       "2008-01-07  29.4683524173  30.6233 -159879000.0  1.544779e+08   \n",
       "2008-01-08  28.2993127955  30.4915 -193525000.0  1.295549e+08   \n",
       "\n",
       "            Real Upper Band  Real Middle Band  Real Lower Band      MFI  \\\n",
       "2008-01-02          31.7512           31.1368          30.5223  44.7185   \n",
       "2008-01-03          31.6972           31.0191          30.3410  46.8154   \n",
       "2008-01-04          31.9971           30.8695          29.7420  34.6668   \n",
       "2008-01-07          32.2614           30.6233          28.9851  35.1914   \n",
       "2008-01-08          32.2283           30.4915          28.7546  20.4535   \n",
       "\n",
       "                SAR       T3     MOM  MIDPRICE      WMA  \n",
       "2008-01-02  33.5787  31.5512 -0.4580   30.9037  31.0630  \n",
       "2008-01-03  33.4331  31.4181 -1.1767   30.8181  30.9294  \n",
       "2008-01-04  33.2498  31.2575 -1.4955   30.4154  30.6566  \n",
       "2008-01-07  32.9925  31.0516 -2.4627   30.2479  30.2800  \n",
       "2008-01-08  32.6870  30.8224 -1.3183   29.9841  30.0907  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicators.rename(columns={'close': 'Close'}, inplace=True)\n",
    "indicators.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "daa51cf7-025f-49d9-9e92-f42b789b60cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indicators['NextDay'] = prices.index.shift(-1, freq='d')\n",
    "\n",
    "y = indicators.iloc[:, 0]\n",
    "X = indicators.iloc[:, 1:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "#y = y[:-1]\n",
    "#X = X[1:, :]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "y_train = y_train.to_numpy().astype(float)\n",
    "y_test = y_test.to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "142067ca-00cc-4457-80fa-27fa35d252fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9346977916617255"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeRegressor()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b77d53eb-355b-4111-b8ed-e025b6063de5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-f16f4dfe854f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test[50].reshape(1,-1), y_test[50])\n",
    "accuracy_score(y_, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "02fb9d60-3fb0-4cb0-8e27-dc0706a75361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9255267396985659"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "regr = svm.SVR()\n",
    "regr = regr.fit(X_train, y_train)\n",
    "regr.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
